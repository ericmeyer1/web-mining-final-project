# Web Mining & NLP Final Project: Using Web Mining & NLP Techniques to Summarize an Article

## Summary
In this project, we use Python's requests module to scrape data from the URL: (https://mitsloan.mit.edu/ideas-made-to-matter/ai-manufacturing-start-data).
Next, we utilized modules beautifulsoup4 and html5lib to parse the webpage data and allow us to further conduct analysis.
Then, we leveraged the spaCy module "en_core_web_sm" model along with the collections - counter to conduct NLP on the webpages data.
Finally, we used matplotlib to visualize the findings of frequent tokens and lemmas in the webpage's sentences.

## Skills Used
- VS Code
- GitHub
- Git
- Python
- Jupyter

## Libraries and Modules
- __Requests:__ Used to make HTTP request to gather webpage data.
- __beautifulsoup4:__ Used to parse the returned webpage results.
- __html5lib:__ Also used to parse the returned webpage results.
- __spaCy:__ Used to setup our model and conduct natural language processing.
- __matplotlib:__ Used to customize data vizualization of our returned NLP results.

## Commands Used to Setup and Activate Virtual Environment
- Creating:
  - python -m venv "name-of-your-environment"
- Activating (for Windows):
  - "name-of-your-environment"\Scripts\Activate

## Commands Used to Download Packages
- python -m pip install jupyter
- python -m pip install ipykernel
- python -m pip install beautifulsoup4
- python -m pip install html5lib
- python -m pip install requests
- python -m pip install spacy

## Download and Setup of spaCy
https://spacy.io/usage

## Interested in chatting about this project, data analytics, or just staying in touch?
Connect with me on LinkedIn: [Eric Meyer](https://www.linkedin.com/in/ericmeyer123/)
